# Workers Brief Explanation

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DECLARATIVE SYSTEM                        â”‚
â”‚                                                              â”‚
â”‚  API â†’ Reconciler â†’ Operation Queue â†’ Worker â†’ KubeDB      â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. Reconciliation Worker

### What It Does
**Detects drift** between what you want (desired state) and what's actually running (current state), then creates operations to fix the drift.

### Core Concept
```python
if desired_state != current_state:
    create_operation_to_fix_it()
```

### Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  RECONCILIATION WORKER                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Every 10-30 seconds:

1. Fetch all databases from MongoDB
   â”œâ”€ db.size (desired)
   â”œâ”€ db.current_size (actual)
   â””â”€ db.replicas, storage_gb, etc.

2. For each database:
   â”œâ”€ Get KubeDB CR from Kubernetes
   â”œâ”€ Parse current state (replicas, storage, size)
   â””â”€ Update db.current_* fields

3. Compare desired vs current:
   â”œâ”€ size != current_size? â†’ Create SCALE_VERTICAL operation
   â”œâ”€ replicas != current_replicas? â†’ Create SCALE_HORIZONTAL operation
   â””â”€ storage_gb != current_storage_gb? â†’ Create EXPAND_STORAGE operation

4. Enqueue operations to Redis queue
   â””â”€ With deduplication (won't create duplicates)

5. Sleep and repeat
```

### Example

```python
# Database state:
db.size = "db.t3.large"           # Desired (user wants)
db.current_size = "db.t3.medium"   # Current (actually running)

# Reconciler detects:
"db.t3.large != db.t3.medium"  â†’ DRIFT!

# Action:
operation = Operation(
    type="SCALE_VERTICAL",
    desired_state={"size": "db.t3.large"}
)
â†’ Enqueue to Redis
```

### Key Features
- âœ… **Runs continuously** (background loop)
- âœ… **Read-only** (only reads Kubernetes, doesn't modify)
- âœ… **Deduplication** (won't spam operations)
- âœ… **Self-healing** (detects manual changes and reverts)

### Configuration
```bash
RECONCILE_INTERVAL=30  # Seconds between cycles (default: 30)
```

---

## 2. Operation Worker

### What It Does
**Executes operations** by creating KubeDB OpsRequests and monitoring them until complete.

### Core Concept
```python
operation = dequeue_from_redis()
execute(operation)  # Create OpsRequest, wait for KubeDB
update_current_state()  # Sync back to database
```

### Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OPERATION WORKER                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Continuous loop:

1. Dequeue operation from Redis
   â””â”€ Blocking wait (1 second timeout)

2. Load operation & database from MongoDB
   â””â”€ Validate both exist

3. Mark operation as IN_PROGRESS
   â””â”€ Update status, timestamps

4. Execute based on type:

   A. SCALE_VERTICAL (CPU/Memory):
      â”œâ”€ Create MongoDBOpsRequest in Kubernetes
      â”œâ”€ Monitor every 5 seconds
      â”‚  â”œâ”€ Phase: Pending â†’ Progressing â†’ Successful
      â”‚  â””â”€ Update progress: 30% â†’ 90% â†’ 100%
      â””â”€ Wait for completion (~30 seconds)

   B. SCALE_HORIZONTAL (Replicas):
      â”œâ”€ Patch MongoDB CR directly
      â””â”€ Quick (~5 seconds)

   C. EXPAND_STORAGE:
      â”œâ”€ Patch MongoDB CR directly
      â””â”€ Quick (~5 seconds)

5. Update database current_* fields:
   â””â”€ db.current_size = desired_size
   â””â”€ db.current_replicas = desired_replicas

6. Cleanup:
   â””â”€ Delete OpsRequest from Kubernetes

7. Mark operation as COMPLETED
   â””â”€ Remove from queue

8. Repeat (dequeue next operation)
```

### Example (Vertical Scaling)

```python
# Operation details:
operation.type = "SCALE_VERTICAL"
operation.desired_state = {"size": "db.t3.large"}

# Worker executes:
Step 1: Create OpsRequest
  â””â”€ Name: "pankaj123-demo-demo-scale-1764670590"
  â””â”€ Resources: CPU=2, Memory=4Gi

Step 2: Monitor OpsRequest (every 5 seconds)
  00:00 - Phase: Pending (Progress: 30%)
  00:05 - Phase: Progressing (Progress: 50%)
  00:25 - Phase: Successful (Progress: 100%)

Step 3: Update database
  â””â”€ db.current_size = "db.t3.large"

Step 4: Delete OpsRequest
  â””â”€ Cleanup from Kubernetes

Step 5: Done!
  â””â”€ Duration: ~30 seconds
```

### Key Features
- âœ… **Asynchronous** (non-blocking)
- âœ… **Progress tracking** (0% â†’ 100%)
- âœ… **Retry logic** (max 3 retries)
- âœ… **Timeout handling** (10 minutes max)
- âœ… **Auto cleanup** (deletes OpsRequests)
- âœ… **Scalable** (run multiple workers)

---

## How They Work Together

### Full Lifecycle Example

```
USER ACTION:
PATCH /databases/db-123 {"size": "db.t3.large"}
â†“

API LAYER:
- Validates request
- Updates: db.size = "db.t3.large" (desired state)
- Returns immediately (< 50ms)
- Does NOT create operations

â†“

RECONCILER (Next Cycle - Every 30s):
1. Reads database from MongoDB:
   - Desired: db.size = "db.t3.large"
   - Current: db.current_size = "db.t3.medium"

2. Reads KubeDB CR from Kubernetes:
   - Actual resources: CPU=1, Memory=2Gi

3. Compares:
   - "db.t3.large != db.t3.medium" â†’ DRIFT!

4. Creates operation:
   - Type: SCALE_VERTICAL
   - Desired: {"size": "db.t3.large"}

5. Enqueues to Redis

â†“

OPERATION WORKER:
1. Dequeues operation from Redis

2. Marks as IN_PROGRESS

3. Creates MongoDBOpsRequest:
   - Name: "db-123-scale-1764670590"
   - CPU: 2, Memory: 4Gi

4. Monitors every 5 seconds:
   - Pending â†’ Progressing â†’ Successful

5. Updates current state:
   - db.current_size = "db.t3.large"

6. Deletes OpsRequest

7. Marks as COMPLETED

â†“

RECONCILER (Next Cycle):
1. Compares:
   - Desired: "db.t3.large"
   - Current: "db.t3.large"

2. No drift! âœ…

3. No operation needed

â†“

SYSTEM STABLE âœ…
```

---

## Key Differences

| Aspect | Reconciler | Worker |
|--------|-----------|--------|
| **Role** | Detect drift | Execute changes |
| **Reads from** | MongoDB + Kubernetes | MongoDB + Redis |
| **Writes to** | MongoDB (current_*) + Redis | MongoDB (current_*) + Kubernetes |
| **Runs** | Every 30 seconds | Continuously (polls queue) |
| **Speed** | Fast (reads only) | Slow (waits for KubeDB) |
| **Concurrency** | 1 instance only | Multiple instances OK |
| **Creates** | Operations | OpsRequests |

---

## Deduplication

### Problem Without Deduplication
```
Reconciler Cycle 1: Creates operation "scale to large"
Reconciler Cycle 2: Creates operation "scale to large" (duplicate!)
Reconciler Cycle 3: Creates operation "scale to large" (duplicate!)
â†’ 3 operations for same change!
```

### Solution: Dedup Key
```python
dedup_key = f"{database_id}:{operation_type}"
# Example: "db-123:scale_vertical"

# Redis checks:
if dedup_key exists in queue:
    reject_operation()  # Duplicate!
else:
    enqueue_operation()
    store_dedup_key()
```

### Result
```
Reconciler Cycle 1: Creates operation âœ…
Reconciler Cycle 2: Duplicate detected, skipped âœ…
Reconciler Cycle 3: Duplicate detected, skipped âœ…
â†’ Only 1 operation created!
```

---

## State Management

### Two Types of State

**Desired State** (What user wants):
```python
db.size = "db.t3.large"
db.replicas = 3
db.storage_gb = 50
```

**Current State** (What's actually running):
```python
db.current_size = "db.t3.medium"
db.current_replicas = 3
db.current_storage_gb = 50
```

### Who Updates What

**API Updates:**
- âœ… Desired state (`db.size`, `db.replicas`, `db.storage_gb`)
- âŒ Current state (never touches current_*)

**Reconciler Updates:**
- âŒ Desired state (never touches it)
- âœ… Current state (syncs from KubeDB CR)
- âš ï¸ **Only if value is not None** (after fix)

**Worker Updates:**
- âŒ Desired state (never touches it)
- âœ… Current state (after operation completes)

---

## Error Handling

### Reconciler Errors
```python
try:
    reconcile_database()
except Exception as e:
    log_error(e)
    continue  # Move to next database
    # Don't crash - keep running
```

### Worker Errors
```python
try:
    execute_operation()
except Exception as e:
    mark_as_failed()

    if can_retry():  # retry_count < 3
        requeue_with_higher_priority()
    else:
        mark_database_as_failed()
```

---

## Monitoring

### Key Metrics

**Reconciler:**
```prometheus
dbaas_reconciliation_cycle_total
dbaas_drift_detected_total{type="size|replicas|storage"}
dbaas_operations_created_total{source="reconciler"}
```

**Worker:**
```prometheus
dbaas_operations_completed_total{type="scale_vertical",status="completed"}
dbaas_operation_duration_seconds
dbaas_worker_busy{worker_id="1"}
```

### Key Logs

**Reconciler:**
```log
[info] reconciliation_started provider_count=2
[info] size_drift_detected desired=db.t3.large current=db.t3.medium
[info] drift_detected_creating_operations operation_count=1
[info] reconciliation_completed
```

**Worker:**
```log
[info] processing_operation operation_id=op-abc123
[info] creating_ops_request ops_request_name=db-scale-1234
[info] ops_request_successful duration=28.5s
[info] operation_completed
```

---

## Scaling

### Reconciler: DO NOT SCALE
```bash
# WRONG - Creates duplicate operations!
docker-compose up --scale reconciler=3  # âŒ

# CORRECT - Only 1 instance
docker-compose up --scale reconciler=1  # âœ…
```

### Worker: SCALE FREELY
```bash
# CORRECT - Higher throughput
docker-compose up --scale worker=5  # âœ…

# Each worker processes different operations
# Redis queue distributes work
```

---

## Summary

**Reconciler:**
- ğŸ” **Detective** - Finds problems (drift)
- ğŸ“‹ **Planner** - Creates operations to fix them
- ğŸ”„ **Continuous** - Runs every 30 seconds
- ğŸ¯ **Single instance** - Must be only 1

**Worker:**
- ğŸ”¨ **Executor** - Does the actual work
- â±ï¸ **Patience** - Waits for KubeDB to finish
- ğŸ“Š **Reporter** - Updates progress & state
- ğŸš€ **Scalable** - Can run multiple instances

**Together:**
- âœ… **Eventually consistent** system
- âœ… **Self-healing** (detects & fixes drift)
- âœ… **Kubernetes-native** pattern
- âœ… **Production-ready** architecture

---

**Think of it like:**
- **Reconciler** = Quality Inspector (checks if things match specs)
- **Worker** = Factory Worker (builds/fixes things)
- **API** = Sales Team (takes orders from customers)
- **Redis Queue** = Task Board (tracks what needs to be done)
